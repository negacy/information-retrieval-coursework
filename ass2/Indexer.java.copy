//package edu.ucdenver.ccp.nlp.ass2;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.StringField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.queryparser.classic.ParseException;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TopScoreDocCollector;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.RAMDirectory;
import org.apache.lucene.util.Version;

import java.io.IOException;
import java.io.FileReader;
import java.io.BufferedReader;

import java.util.HashMap;
import java.util.Map;
import java.util.ArrayList;
import java.util.List;

public class Indexer {

	public static void main(String args []) throws IOException, ParseException{

		BufferedReader br = new BufferedReader(new FileReader(args[0]));
		String line = null;
		String docID =  "";
		String docAbstract = "";
		Map<String, String> dictionary = new HashMap<String, String>();	//dictionary to store docId and abstract for each article
        
        Map<String, List<String>> dictPredict = new HashMap<String, List<String>>(); //stores retrieved doc for each query
        Map<String, List<String>> dictGold = new HashMap<String, List<String>>(); //stores human gugement relevant document for each query
         
		// 0. Specify the analyzer for tokenizing text.
		//    The same analyzer should be used for indexing and searching
		StandardAnalyzer analyzer = new StandardAnalyzer(Version.LUCENE_40);

		// 1. create the index
		Directory index = new RAMDirectory();

		IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_40, analyzer);

		IndexWriter w = new IndexWriter(index, config);
		while ((line = br.readLine()) != null) {
			if (line.startsWith(".I")) {
				docID = "";
				docAbstract = "";
				}
			if (line.startsWith(".U")) {
				docID = br.readLine();
				}
			if(line.startsWith(".W")) {
				docAbstract = br.readLine();
			}
			dictionary.put(docID, docAbstract);
			//addDoc(w, docAbstract, docID);
		}
		for (Map.Entry<String, String> entry : dictionary.entrySet())	{
			if (entry.getValue() != "") 
			//System.out.println(entry.getKey() + "/" + entry.getValue());
			addDoc(w, entry.getValue(), entry.getKey());
		}
  		w.close();
		br.close();
	
		 // 2. query
		
		br = new BufferedReader(new FileReader(args[1]));	
		String [] number = new String[100];
		String [] myQuery = new String[100];
		int countNum = 0;
		int countTitle = 0;
		while ((line = br.readLine()) != null) {
			if (line.startsWith("<num>")) {
				//System.out.print(line);
				number[countNum++] = line.split("Number:")[1].replaceAll("\\s+","");
				}
			else if (line.startsWith("<title>")) {
				//System.out.print("\t" + line);
				myQuery[countTitle] = line.split("title>")[1] + ' ';
				}
			else if (line.startsWith("<desc>")) {
				//System.out.println("\t" + br.readLine());
				myQuery[countTitle++] += br.readLine();
				}
			
			}
		br.close();
		
		String querystr = null; //"60 year old menopausal woman without hormone replacement therapy";//args.length > 0 ? args[0] : "lucene";
		int count = 0;
		for (String s: myQuery) {
				querystr = s;
				if (querystr != null) { //avoid null queries
						//System.out.print(number[count++] + "\t");// + "\tq: " + querystr);			
						// the "title" arg specifies the default field to use
						// when no field is explicitly specified in the query.
						Query q = new QueryParser(Version.LUCENE_40, "title", analyzer).parse(querystr);

						// 3. search
						int hitsPerPage = 7;
						IndexReader reader = DirectoryReader.open(index);
						IndexSearcher searcher = new IndexSearcher(reader);
						TopScoreDocCollector collector = TopScoreDocCollector.create(hitsPerPage, true);
						searcher.search(q, collector);
						ScoreDoc[] hits = collector.topDocs().scoreDocs;
						// 4. display results
						//System.out.println("Found " + hits.length + " hits.");

                        //declare temporary List to store retrieved docIds for each query
                        List<String> retrievedDocs = new ArrayList<String>();

						for(int i=0;i<hits.length;++i) {
							int docId = hits[i].doc;
							Document d = searcher.doc(docId);
							System.out.println(number[count] + "\t" + d.get("isbn") + '\t');
							//System.out.println((i + 1) + ". " + d.get("isbn") + "\t" + d.get("title"));
                            //populate dictPredict
                            retrievedDocs.add(d.get("isbn"));
						}
                        dictPredict.put(number[count], retrievedDocs);
						count++; //process next query
						//System.out.println();
		
				// reader can only be closed when there
   				// is no need to access the documents any more.
    			reader.close();
			}
		}	
    //call rprecision method
    rPrecision(dictPredict);	
	} //main

    private static void addDoc(IndexWriter w, String title, String isbn) throws IOException {
    Document doc = new Document();
    doc.add(new TextField("title", title, Field.Store.YES));

    // use a string field for isbn because we don't want it tokenized
    doc.add(new StringField("isbn", isbn, Field.Store.YES));
    w.addDocument(doc);
    }
    
    private static void rPrecision(Map<String, List<String>> dictPredict){//, Map<String, String> dictGold) {
        System.out.println("predict values ...");
		for (Map.Entry<String, List<String>> entry : dictPredict.entrySet())    {
            String key = entry.getKey();
            List<String> values = entry.getValue();
            System.out.println("Key = " + key);
            System.out.println("Values = " + values + "n");
            //System.out.println(entry.getKey() + "/" + entry.getValue());
		}
        /*
        System.out.println("Gold values ...");

		for (Map.Entry<String, String> entry : dictGold.entrySet())	{
		    System.out.println(entry.getKey() + "/" + entry.getValue());
		}
        */

    }
}
